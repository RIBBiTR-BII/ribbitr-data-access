---
title: "4. Data Workflow"
author: "Cob Staines"
date: today
toc: true
format:
  html: 
    code-line-numbers: false
  pdf:
    code-line-numbers: false
    geometry: 
      - top=30mm
      - left=30mm
---

```{r setup, include=FALSE}
librarian::shelf(reticulate)
# use_python("/home/cob/miniconda3/envs/ribbitr/bin/python")
use_condaenv("ribbitr", required = TRUE)
```

# Motivation
- Familiarize ourselves with more data manipulation tools
- Run through a complete workflow including: database connection, data discovery, data pulling, and data manipulation

::: {.panel-tabset}

# R Data Workflow
Let's run through a realistic data scenario from the beginning.

## Setup

These setup steps will all be familiar to you by now.
```{r, message=FALSE}
# minimal packages for RIBBiTR DB data discovery
librarian::shelf(tidyverse, dbplyr, RPostgres, DBI, RIBBiTR-BII/ribbitrrr)

# establish database connection
dbcon = hopToDB("ribbitr")

# load table metadata
mdt = tbl(dbcon, Id("public", "all_tables")) %>%
  filter(table_schema == "survey_data") %>%
  collect()

# load column metadata
mdc = tbl(dbcon, Id("survey_data", "metadata_columns")) %>%
  filter(table_schema == "survey_data") %>%
  collect()
```

## Data discovery and pulling

Suppose we are interested in capture and Bd swab data. Specifically, we want to compare Bd qPCR results for juvenile-to-adult individuals, captured in 2015 or later, across species and sites.

Looking at the table metadata, the two observation tables with most of the data of interest are called "capture" and "bd_qpcr_results".

#### Pull capture table

```{r}
# capture table, select, filter
db_capture = tbl(dbcon, Id("survey_data", "capture")) %>%
  select(species_capture,
         body_temp_c,
         life_stage,
         sex,
         capture_animal_state,
         bd_swab_id,
         survey_id)

```

#### Join with support tables, filter by date

```{r}

# create chain object
chain_capture = tbl_chain("capture", mdc)

# join recursively, filter by date
db_capture_chain = tbl_join(dbcon, chain_capture, tbl = db_capture) %>%
  filter(date >= "2015-01-01")

```

#### Join with Bd table
```{r}
db_bd_results = tbl(dbcon, Id("survey_data", "bd_qpcr_results")) %>%
  select(bd_swab_id,
         detected,
         average_target_quant)

db_capture_bd = db_capture_chain %>%
  inner_join(db_bd_results, by="bd_swab_id")
```

#### Explore # of samples by life stage, then filter
```{r}

db_capture_bd %>%
  select(life_stage) %>%
  group_by(life_stage) %>%
  summarise(row_count = n()) %>%
  arrange(desc(row_count)) %>%
  collect()

db_capture_bd_life = db_capture_bd %>%
  filter(life_stage %in% c("juvenile",
                           "subadult",
                           "adult"),
         !is.na(life_stage))

```

#### Explore # of samples by species, then filter

```{r}

(spp_summary = db_capture_bd_life%>%
  select(species_capture) %>%
  group_by(species_capture) %>%
  summarise(sample_count = n()) %>%
  arrange(desc(sample_count)) %>%
  collect())

(spp_list = spp_summary %>%
  filter(sample_count >= 100) %>%
  pull(species_capture))

db_capture_bd_life_spp = db_capture_bd_life %>%
  filter(species_capture %in% spp_list,
         !is.na(species_capture))

```
#### collect data

```{r}

data_capture_bd_query = db_capture_bd_life_spp %>%
  collect()

colnames(data_capture_bd_query)

head(data_capture_bd_query)

```

These data are ready to be analyzed and visualized!

# Python Data Workflow
Let's run through a realistic data scenario from the beginning.

## Setup

These setup steps will all be familiar to you by now.
```{python, message=FALSE}
# minimal packages for RIBBiTR DB Workflow
import ibis
from ibis import _
import pandas as pd
import dbconfig
import db_access as db

# establish database connection
dbcon = ibis.postgres.connect(**dbconfig.ribbitr)

# load table metadata
mdt = dbcon.table(database = "public", name = "all_tables").to_pandas()

# load column metadata
mdc = (
  dbcon.table(database="public", name="all_columns")
  .filter(_.table_schema == 'survey_data')
  .to_pandas()
  )
```

## Data discovery and pulling

Suppose we are interested in capture and Bd swab data. Specifically, we want to compare Bd qPCR results for juvenile-to-adult individuals, captured in 2015 or later, across species and sites.

Looking at the table metadata, the two observation tables with most of the data of interest are called "capture" and "bd_qpcr_results".

#### Pull capture table

```{python}
# capture table, select, filter
db_capture = (
  dbcon.table(database="survey_data", name="capture")
  .select([
    'species_capture',
    'body_temp_c',
    'life_stage',
    'sex',
    'capture_animal_state',
    'bd_swab_id',
    'survey_id'
    ])
  )

```

#### Join with support tables, filter to date

```{python}

# create chain object
chain_capture = db.tbl_chain("capture", mdc)

# join recursively, filter by date
db_capture_chain = (
  db.tbl_join(dbcon, chain_capture, tbl=db_capture)
  .filter(_.date >= '2015-01-01')
  )

```

#### Join with Bd table
```{python}
# bd qpcr results lazy table
db_bd_results = (
  dbcon.table(database="survey_data", name="bd_qpcr_results")
  .select([
    'bd_swab_id',
    'detected',
    'average_target_quant'
  ])
  )

# join capture and bd tables
db_capture_bd = (
  db_capture_chain
  .inner_join(db_bd_results, db_capture_chain.bd_swab_id == db_bd_results.bd_swab_id)
  )

```

#### Explore # of samples by life stage, then filter
```{python}
# count by life stage
life_stage_counts = (
  db_capture_bd
  .group_by('life_stage')
  .aggregate(row_count=_.count())
  .order_by(_.row_count.desc())
  .to_pandas()
  )

print(life_stage_counts)

# filter to desired life stages
db_capture_bd_life = (
  db_capture_bd
  .filter(_.life_stage.isin(['juvenile','subadult', 'adult']) & _.life_stage.notnull())
  )
```

#### Explore # of samples by species, then filter

```{python}
# count by species
spp_summary = (
  db_capture_bd_life
  .group_by('species_capture')
  .aggregate(sample_count=_.count())
  .order_by(_.sample_count.desc())
  .to_pandas()
  )
print(spp_summary)

# generate species list
spp_list = spp_summary[spp_summary['sample_count'] >= 100]['species_capture'].tolist()

# filter to species in spp_list
db_capture_bd_life_spp = (
  db_capture_bd_life
  .filter(_.species_capture.isin(spp_list) & _.species_capture.notnull())
  )

```

#### Pull data

```{python}
# pull data
data_capture_bd_query = db_capture_bd_life_spp.to_pandas()

# printcolumn names
data_capture_bd_query.columns

# preview data
data_capture_bd_query.head()
```

These data are ready to be analyzed and visualized!

:::
<div style="text-align: center;">
[Previous Tutorial: Data Pulling](03_data_pulling.html)
</div>