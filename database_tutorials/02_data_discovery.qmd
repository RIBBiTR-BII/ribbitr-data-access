---
title: "RIBBiTR Database Data Discovery"
author: "Cob Staines"
date: today
format:
  html: 
    code-line-numbers: false
  pdf:
    code-line-numbers: false
    geometry: 
      - top=30mm
      - left=30mm
---

# Motivation
# Database Data Discovery with RStudio

## Load packages

```{r, message=FALSE}
# install and load "librarian" package if not already required
if (!require(librarian)) {
  install.packages("librarian")
  library(librarian)
}

# minimal packages for RIBBiTR DB data discovery
shelf(tidyverse, RPostgres, DBI, RIBBiTR-BII/ribbitrrr)
```

## Establish database connection

```{r}
# establish database connection
dbcon = HopToDB("ribbitr")
```

## Load database metadata
The ribbitr database is organized into "schemas" (think of these as folders), which can contain any number of tables. Each table consists of columns ("variables") and rows ("entries"). We keep track of information regarding what tables, and columns exist in the database using table and column metadata. To begin our process of data discovery, let's load the table and column metadata

```{r}
# load table "all_tables" from schema "public"
mdt = tbl(dbcon, Id("public", "all_tables")) %>%
  collect()

```

Before we dive into the metadata you just pulled, let's understand the commands we just ran.
- tbl() - This function is used to create a "lazy" table from a data source. To specify the source, we provide the database connection "dbcon" as well as the pointer using the Id() function. A "lazy" table means that the data only pulled when explicitly asked for. See collect() below.
- Id() - This function is a pointer to pass hierarchical table identifiers. In this case we use it to generate an identifier for the table "all_tables" in schema "public".
- collect() - the tbl() function generates a lazy table, which is basically a shopping list. In order to pull the data from the server to your local machine (ie. "do the shopping") we need to pipe in the collect function.

Try running the code above without the collect() function, to see what a lazy table looks like.

```{r}
view(mdt)
```

```{r}
# load table "all_columns" from schema "public"
mdc = tbl(dbcon, Id("public", "all_columns")) %>%
  filter(table_schema == "survey_data") %>%
  collect()
```

```{r}
# eventually these should go in the ribbitr R package

pkey = function(table_str, metadata_columns=metadata_columns) {
  metadata_columns %>%
    filter(table_name == table_str,
           key_type == "PK") %>%
    pull(column_name)
}

fkey = function(table_str, metadata_columns=metadata_columns) {
  metadata_columns %>%
    filter(table_name == table_str,
           key_type == "FK") %>%
    pull(column_name)
}

nkey = function(table_str, metadata_columns=metadata_columns) {
  metadata_columns %>%
    filter(table_name == table_str,
           natural_key) %>%
    pull(column_name)
}
```

## Load required libraries

```{r}
# install and load librarian if not already required
if (!require(librarian)){
  install.packages("librarian")
  library(librarian)
}

# librarian downloads and loads required packages listed below
librarian::shelf(RPostgres, DBI, tidyverse, dbplyr, here)
```

## Establish database connection

```{r}
tryCatch({
  cat("Connecting to database... ")
  dbcon <- dbConnect(dbDriver("Postgres"),
                          dbname = Sys.getenv("aws_dbname"),
                          host = Sys.getenv("aws_host"),
                          port = Sys.getenv("aws_port"),
                          user = Sys.getenv("aws_user"),
                          password = Sys.getenv("aws_password"),
                          timezone=NULL)
  cat("Connected!")
},
error=function(coms) {
  message("Unable to connect: ", coms$message)
})
```

## Explore the database

### Accessing database table metadata

```{r}
# using dbplyr
dbp_tables = tbl(dbcon, Id("public", "all_tables")) %>%
  collect()

# using SQL
sql_tables_q = "SELECT * FROM ribbitr.public.all_tables"
sql_tables = dbGetQuery(dbcon, sql_tables_q)

```

### Accessing database column metadata

A simple filter: Suppose that, after looking through the database tables, we are only interested in tables within the "survey_data" schema.

```{r}
# using dbplyr
dbp_columns = tbl(dbcon, Id("public", "all_columns")) %>%
  filter(table_schema == "survey_data") %>%
  collect()

# using SQL + DBI
sql_columns_q = "SELECT * FROM ribbitr.public.all_columns
                 WHERE table_schema = 'survey_data'"
sql_columns = dbGetQuery(dbcon, sql_columns_q)

```

### Accessing data

Having explored the table and column metadata from the survey_data schema, we are interested in taking a closer look at the data from the capture table.

```{r}
# using dbplyr
dbp_capture = tbl(dbcon, Id("survey_data", "capture")) %>%
  select(pkey("capture", dbp_columns),
         nkey("capture", dbp_columns), # nothing here, meow! I wonder what to do.
         fkey("capture", dbp_columns)) %>%
  collect()

# using SQL + DBI
sql_capture_q = paste0("SELECT ",
                       paste(c(pkey("capture", dbp_columns),
                               nkey("capture", dbp_columns),
                               fkey("capture", dbp_columns)),
                              collapse = ", "),
                       " FROM ribbitr.survey_data.capture")
sql_capture = dbGetQuery(dbcon, sql_capture_q)

```

### Data chains function (in dev)

-one_link_up -n_links_up -to_table -all_links_up
